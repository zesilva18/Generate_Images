{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import optim\n",
    "import os\n",
    "import torchvision.utils as vutils\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import matplotlib as plt\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Arguments\n",
    "BATCH_SIZE = 64\n",
    "Z_DIM = 100\n",
    "LABEL_EMBED_SIZE = 5\n",
    "NUM_CLASSES = 10\n",
    "IMGS_TO_DISPLAY_PER_CLASS = 20\n",
    "LOAD_MODEL = False\n",
    "\n",
    "DB = 'SVHN'\n",
    "\n",
    "CHANNELS = 3\n",
    "EPOCHS = 100\n",
    "\n",
    "# Directories for storing data, model and output samples\n",
    "db_path = os.path.join('./data', DB)\n",
    "os.makedirs(db_path, exist_ok=True)\n",
    "model_path = os.path.join('./model', DB)\n",
    "os.makedirs(model_path, exist_ok=True)\n",
    "samples_path = os.path.join('./samples', DB)\n",
    "os.makedirs(samples_path, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset ImageFolder\n",
      "    Number of datapoints: 277\n",
      "    Root location: TRAIN\n",
      "    StandardTransform\n",
      "Transform: Compose(\n",
      "               Resize(size=[32, 32], interpolation=bilinear, max_size=None, antialias=warn)\n",
      "               ToTensor()\n",
      "               Normalize(mean=[0.5], std=[0.5])\n",
      "           )\n",
      "<torch.utils.data.dataloader.DataLoader object at 0x000002273B65C310>\n",
      "['12', '13', '24', '38', '39', '44', '46', '49', '50', '6']\n",
      "10\n"
     ]
    }
   ],
   "source": [
    "# Data loader\n",
    "transform = transforms.Compose([transforms.Resize([32, 32]),\n",
    "                                transforms.ToTensor(),\n",
    "                                transforms.Normalize([0.5], [0.5])])\n",
    "\n",
    "\n",
    "train_dataset = datasets.ImageFolder(root='TRAIN', transform=transform)\n",
    "\n",
    "print(train_dataset)\n",
    "\n",
    "\n",
    "data_loader = DataLoader(dataset=train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=4)\n",
    "\n",
    "print(data_loader)\n",
    "\n",
    "#show labels of the dataset\n",
    "\n",
    "print(train_dataset.classes)\n",
    "print(len(train_dataset.classes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Method for storing generated images\n",
    "def generate_imgs(z, fixed_label, epoch=0):\n",
    "    gen.eval()\n",
    "    fake_imgs = gen(z, fixed_label)\n",
    "    fake_imgs = (fake_imgs + 1) / 2\n",
    "    fake_imgs_ = vutils.make_grid(fake_imgs, normalize=False, nrow=IMGS_TO_DISPLAY_PER_CLASS)\n",
    "    vutils.save_image(fake_imgs_, os.path.join(samples_path, 'sample_' + str(epoch) + '.png'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Networks\n",
    "def conv_block(c_in, c_out, k_size=4, stride=2, pad=1, use_bn=True, transpose=False):\n",
    "    module = []\n",
    "    if transpose:\n",
    "        module.append(nn.ConvTranspose2d(c_in, c_out, k_size, stride, pad, bias=not use_bn))\n",
    "    else:\n",
    "        module.append(nn.Conv2d(c_in, c_out, k_size, stride, pad, bias=not use_bn))\n",
    "    if use_bn:\n",
    "        module.append(nn.BatchNorm2d(c_out))\n",
    "    return nn.Sequential(*module)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Generator(nn.Module):\n",
    "    def __init__(self, z_dim=10, num_classes=10, label_embed_size=5, channels=3, conv_dim=64):\n",
    "        super(Generator, self).__init__()\n",
    "        self.label_embedding = nn.Embedding(num_classes, label_embed_size)\n",
    "        self.tconv1 = conv_block(z_dim + label_embed_size, conv_dim * 4, pad=0, transpose=True)\n",
    "        self.tconv2 = conv_block(conv_dim * 4, conv_dim * 2, transpose=True)\n",
    "        self.tconv3 = conv_block(conv_dim * 2, conv_dim, transpose=True)\n",
    "        self.tconv4 = conv_block(conv_dim, channels, transpose=True, use_bn=False)\n",
    "\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d) or isinstance(m, nn.ConvTranspose2d):\n",
    "                nn.init.normal_(m.weight, 0.0, 0.02)\n",
    "\n",
    "            if isinstance(m, nn.BatchNorm2d):\n",
    "                nn.init.constant_(m.weight, 1)\n",
    "                nn.init.constant_(m.bias, 0)\n",
    "\n",
    "    def forward(self, x, label):\n",
    "        x = x.reshape([x.shape[0], -1, 1, 1])\n",
    "        label_embed = self.label_embedding(label)\n",
    "        label_embed = label_embed.reshape([label_embed.shape[0], -1, 1, 1])\n",
    "        x = torch.cat((x, label_embed), dim=1)\n",
    "        x = F.relu(self.tconv1(x))\n",
    "        x = F.relu(self.tconv2(x))\n",
    "        x = F.relu(self.tconv3(x))\n",
    "        x = torch.tanh(self.tconv4(x))\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Discriminator(nn.Module):\n",
    "    def __init__(self, num_classes=10, channels=3, conv_dim=64):\n",
    "        super(Discriminator, self).__init__()\n",
    "        self.image_size = 32\n",
    "        self.label_embedding = nn.Embedding(num_classes, self.image_size*self.image_size)\n",
    "        self.conv1 = conv_block(channels + 1, conv_dim, use_bn=False)\n",
    "        self.conv2 = conv_block(conv_dim, conv_dim * 2)\n",
    "        self.conv3 = conv_block(conv_dim * 2, conv_dim * 4)\n",
    "        self.conv4 = conv_block(conv_dim * 4, 1, k_size=4, stride=1, pad=0, use_bn=False)\n",
    "\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                nn.init.normal_(m.weight, 0.0, 0.02)\n",
    "\n",
    "            if isinstance(m, nn.BatchNorm2d):\n",
    "                nn.init.constant_(m.weight, 1)\n",
    "                nn.init.constant_(m.bias, 0)\n",
    "\n",
    "    def forward(self, x, label):\n",
    "        alpha = 0.2\n",
    "        label_embed = self.label_embedding(label)\n",
    "        label_embed = label_embed.reshape([label_embed.shape[0], 1, self.image_size, self.image_size])\n",
    "        x = torch.cat((x, label_embed), dim=1)\n",
    "        x = F.leaky_relu(self.conv1(x), alpha)\n",
    "        x = F.leaky_relu(self.conv2(x), alpha)\n",
    "        x = F.leaky_relu(self.conv3(x), alpha)\n",
    "        x = torch.sigmoid(self.conv4(x))\n",
    "        return x.squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape from generator: torch.Size([1, 3, 32, 32])\n",
      "Output from discriminator: torch.Size([])\n"
     ]
    }
   ],
   "source": [
    "gen = Generator(z_dim=Z_DIM, num_classes=NUM_CLASSES, label_embed_size=LABEL_EMBED_SIZE, channels=CHANNELS)\n",
    "dis = Discriminator(num_classes=NUM_CLASSES, channels=CHANNELS)\n",
    "\n",
    "\n",
    "# Teste unitário para verificar a saída do gerador\n",
    "test_noise = torch.randn(1, Z_DIM)\n",
    "test_label = torch.LongTensor([1])  # Exemplo de label\n",
    "gen_output = gen(test_noise, test_label)\n",
    "print(\"Output shape from generator:\", gen_output.shape)\n",
    "\n",
    "# Teste unitário para o discriminador\n",
    "dis_output = dis(gen_output, test_label)\n",
    "print(\"Output from discriminator:\", dis_output.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------Generator------------------\n",
      "Generator(\n",
      "  (label_embedding): Embedding(10, 5)\n",
      "  (tconv1): Sequential(\n",
      "    (0): ConvTranspose2d(105, 256, kernel_size=(4, 4), stride=(2, 2), bias=False)\n",
      "    (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  )\n",
      "  (tconv2): Sequential(\n",
      "    (0): ConvTranspose2d(256, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "    (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  )\n",
      "  (tconv3): Sequential(\n",
      "    (0): ConvTranspose2d(128, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  )\n",
      "  (tconv4): Sequential(\n",
      "    (0): ConvTranspose2d(64, 3, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
      "  )\n",
      ")\n",
      "------------------Discriminator------------------\n",
      "Discriminator(\n",
      "  (label_embedding): Embedding(10, 1024)\n",
      "  (conv1): Sequential(\n",
      "    (0): Conv2d(4, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
      "  )\n",
      "  (conv2): Sequential(\n",
      "    (0): Conv2d(64, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "    (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  )\n",
      "  (conv3): Sequential(\n",
      "    (0): Conv2d(128, 256, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "    (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  )\n",
      "  (conv4): Sequential(\n",
      "    (0): Conv2d(256, 1, kernel_size=(4, 4), stride=(1, 1))\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "gen = Generator(z_dim=Z_DIM, num_classes=NUM_CLASSES, label_embed_size=LABEL_EMBED_SIZE, channels=CHANNELS)\n",
    "dis = Discriminator(num_classes=NUM_CLASSES, channels=CHANNELS)\n",
    "\n",
    "# Load previous model   \n",
    "if LOAD_MODEL:\n",
    "    gen.load_state_dict(torch.load(os.path.join(model_path, 'gen.pkl')))\n",
    "    dis.load_state_dict(torch.load(os.path.join(model_path, 'dis.pkl')))\n",
    "    \n",
    "# Model Summary\n",
    "print(\"------------------Generator------------------\")\n",
    "print(gen)\n",
    "print(\"------------------Discriminator------------------\")\n",
    "print(dis)\n",
    "\n",
    "# Define Optimizers\n",
    "g_opt = optim.Adam(gen.parameters(), lr=0.0002, betas=(0.5, 0.999), weight_decay=2e-5)\n",
    "d_opt = optim.Adam(dis.parameters(), lr=0.0002, betas=(0.5, 0.999), weight_decay=2e-5)\n",
    "\n",
    "# Loss functions\n",
    "loss_fn = nn.BCELoss()\n",
    "\n",
    "# Fix images for viz\n",
    "fixed_z = torch.randn(IMGS_TO_DISPLAY_PER_CLASS*NUM_CLASSES, Z_DIM)\n",
    "fixed_label = torch.arange(0, NUM_CLASSES)\n",
    "fixed_label = torch.repeat_interleave(fixed_label, IMGS_TO_DISPLAY_PER_CLASS)\n",
    "\n",
    "\n",
    "# GPU Compatibility\n",
    "is_cuda = torch.cuda.is_available()\n",
    "if is_cuda:\n",
    "    gen, dis = gen.cuda(), dis.cuda()\n",
    "    real_label, fake_label = real_label.cuda(), fake_label.cuda()\n",
    "    fixed_z, fixed_label = fixed_z.cuda(), fixed_label.cuda()\n",
    "\n",
    "total_iters = 0\n",
    "max_iter = len(data_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/100\titer: 0/5\ttotal_iters: 1\td_loss:0.8353\tg_loss:2.5427\n",
      "Epoch: 2/100\titer: 0/5\ttotal_iters: 6\td_loss:0.2418\tg_loss:2.2637\n",
      "Epoch: 3/100\titer: 0/5\ttotal_iters: 11\td_loss:0.1678\tg_loss:2.9562\n",
      "Epoch: 4/100\titer: 0/5\ttotal_iters: 16\td_loss:0.1194\tg_loss:3.1491\n",
      "Epoch: 5/100\titer: 0/5\ttotal_iters: 21\td_loss:0.1049\tg_loss:3.973\n",
      "Epoch: 6/100\titer: 0/5\ttotal_iters: 26\td_loss:0.1029\tg_loss:3.4266\n",
      "Epoch: 7/100\titer: 0/5\ttotal_iters: 31\td_loss:0.4683\tg_loss:6.3576\n",
      "Epoch: 8/100\titer: 0/5\ttotal_iters: 36\td_loss:0.1043\tg_loss:3.8823\n",
      "Epoch: 9/100\titer: 0/5\ttotal_iters: 41\td_loss:0.1255\tg_loss:3.812\n",
      "Epoch: 10/100\titer: 0/5\ttotal_iters: 46\td_loss:0.185\tg_loss:3.9073\n",
      "Epoch: 11/100\titer: 0/5\ttotal_iters: 51\td_loss:0.1935\tg_loss:3.9918\n",
      "Epoch: 12/100\titer: 0/5\ttotal_iters: 56\td_loss:0.1908\tg_loss:3.221\n",
      "Epoch: 13/100\titer: 0/5\ttotal_iters: 61\td_loss:0.2245\tg_loss:4.4102\n",
      "Epoch: 14/100\titer: 0/5\ttotal_iters: 66\td_loss:0.1508\tg_loss:3.442\n",
      "Epoch: 15/100\titer: 0/5\ttotal_iters: 71\td_loss:0.2247\tg_loss:5.4308\n",
      "Epoch: 16/100\titer: 0/5\ttotal_iters: 76\td_loss:0.188\tg_loss:3.4724\n",
      "Epoch: 17/100\titer: 0/5\ttotal_iters: 81\td_loss:0.2201\tg_loss:4.1421\n",
      "Epoch: 18/100\titer: 0/5\ttotal_iters: 86\td_loss:0.3954\tg_loss:3.7416\n",
      "Epoch: 19/100\titer: 0/5\ttotal_iters: 91\td_loss:0.1816\tg_loss:3.8875\n",
      "Epoch: 20/100\titer: 0/5\ttotal_iters: 96\td_loss:0.2808\tg_loss:2.494\n",
      "Epoch: 21/100\titer: 0/5\ttotal_iters: 101\td_loss:0.1826\tg_loss:3.3599\n",
      "Epoch: 22/100\titer: 0/5\ttotal_iters: 106\td_loss:0.3542\tg_loss:4.953\n",
      "Epoch: 23/100\titer: 0/5\ttotal_iters: 111\td_loss:0.2353\tg_loss:3.391\n",
      "Epoch: 24/100\titer: 0/5\ttotal_iters: 116\td_loss:0.2434\tg_loss:3.0364\n",
      "Epoch: 25/100\titer: 0/5\ttotal_iters: 121\td_loss:0.2249\tg_loss:3.2163\n",
      "Epoch: 26/100\titer: 0/5\ttotal_iters: 126\td_loss:0.2603\tg_loss:3.4695\n",
      "Epoch: 27/100\titer: 0/5\ttotal_iters: 131\td_loss:0.205\tg_loss:2.7089\n",
      "Epoch: 28/100\titer: 0/5\ttotal_iters: 136\td_loss:0.2221\tg_loss:3.6324\n",
      "Epoch: 29/100\titer: 0/5\ttotal_iters: 141\td_loss:0.5667\tg_loss:5.3298\n",
      "Epoch: 30/100\titer: 0/5\ttotal_iters: 146\td_loss:0.2769\tg_loss:2.9726\n",
      "Epoch: 31/100\titer: 0/5\ttotal_iters: 151\td_loss:0.1842\tg_loss:3.1559\n",
      "Epoch: 32/100\titer: 0/5\ttotal_iters: 156\td_loss:0.1816\tg_loss:4.1019\n",
      "Epoch: 33/100\titer: 0/5\ttotal_iters: 161\td_loss:0.1663\tg_loss:3.2276\n",
      "Epoch: 34/100\titer: 0/5\ttotal_iters: 166\td_loss:0.1468\tg_loss:3.6151\n",
      "Epoch: 35/100\titer: 0/5\ttotal_iters: 171\td_loss:0.4792\tg_loss:6.4429\n",
      "Epoch: 36/100\titer: 0/5\ttotal_iters: 176\td_loss:0.1393\tg_loss:3.512\n",
      "Epoch: 37/100\titer: 0/5\ttotal_iters: 181\td_loss:0.2369\tg_loss:2.5489\n",
      "Epoch: 38/100\titer: 0/5\ttotal_iters: 186\td_loss:0.4036\tg_loss:3.7477\n",
      "Epoch: 39/100\titer: 0/5\ttotal_iters: 191\td_loss:0.2709\tg_loss:4.5705\n",
      "Epoch: 40/100\titer: 0/5\ttotal_iters: 196\td_loss:0.23\tg_loss:2.6741\n",
      "Epoch: 41/100\titer: 0/5\ttotal_iters: 201\td_loss:0.1424\tg_loss:3.2349\n",
      "Epoch: 42/100\titer: 0/5\ttotal_iters: 206\td_loss:0.1485\tg_loss:3.1307\n",
      "Epoch: 43/100\titer: 0/5\ttotal_iters: 211\td_loss:0.1874\tg_loss:3.1609\n",
      "Epoch: 44/100\titer: 0/5\ttotal_iters: 216\td_loss:0.1099\tg_loss:3.536\n",
      "Epoch: 45/100\titer: 0/5\ttotal_iters: 221\td_loss:0.1133\tg_loss:3.4144\n",
      "Epoch: 46/100\titer: 0/5\ttotal_iters: 226\td_loss:0.1464\tg_loss:3.471\n",
      "Epoch: 47/100\titer: 0/5\ttotal_iters: 231\td_loss:0.1708\tg_loss:2.8421\n",
      "Epoch: 48/100\titer: 0/5\ttotal_iters: 236\td_loss:0.107\tg_loss:3.7414\n",
      "Epoch: 49/100\titer: 0/5\ttotal_iters: 241\td_loss:0.1343\tg_loss:3.6581\n",
      "Epoch: 50/100\titer: 0/5\ttotal_iters: 246\td_loss:0.1907\tg_loss:4.1212\n",
      "Epoch: 51/100\titer: 0/5\ttotal_iters: 251\td_loss:0.1219\tg_loss:3.7639\n",
      "Epoch: 52/100\titer: 0/5\ttotal_iters: 256\td_loss:0.1035\tg_loss:3.3278\n",
      "Epoch: 53/100\titer: 0/5\ttotal_iters: 261\td_loss:0.1013\tg_loss:3.3747\n",
      "Epoch: 54/100\titer: 0/5\ttotal_iters: 266\td_loss:0.5994\tg_loss:5.4649\n",
      "Epoch: 55/100\titer: 0/5\ttotal_iters: 271\td_loss:0.0973\tg_loss:4.1186\n",
      "Epoch: 56/100\titer: 0/5\ttotal_iters: 276\td_loss:0.093\tg_loss:3.595\n",
      "Epoch: 57/100\titer: 0/5\ttotal_iters: 281\td_loss:0.0927\tg_loss:3.9891\n",
      "Epoch: 58/100\titer: 0/5\ttotal_iters: 286\td_loss:0.1294\tg_loss:3.4588\n",
      "Epoch: 59/100\titer: 0/5\ttotal_iters: 291\td_loss:0.1521\tg_loss:3.6667\n",
      "Epoch: 60/100\titer: 0/5\ttotal_iters: 296\td_loss:0.1305\tg_loss:3.7869\n",
      "Epoch: 61/100\titer: 0/5\ttotal_iters: 301\td_loss:0.091\tg_loss:3.2566\n",
      "Epoch: 62/100\titer: 0/5\ttotal_iters: 306\td_loss:0.1182\tg_loss:3.2951\n",
      "Epoch: 63/100\titer: 0/5\ttotal_iters: 311\td_loss:0.1359\tg_loss:3.6488\n",
      "Epoch: 64/100\titer: 0/5\ttotal_iters: 316\td_loss:0.2157\tg_loss:4.4159\n",
      "Epoch: 65/100\titer: 0/5\ttotal_iters: 321\td_loss:0.0964\tg_loss:3.8379\n",
      "Epoch: 66/100\titer: 0/5\ttotal_iters: 326\td_loss:0.1753\tg_loss:4.3885\n",
      "Epoch: 67/100\titer: 0/5\ttotal_iters: 331\td_loss:0.1576\tg_loss:3.4903\n",
      "Epoch: 68/100\titer: 0/5\ttotal_iters: 336\td_loss:0.1005\tg_loss:3.3851\n",
      "Epoch: 69/100\titer: 0/5\ttotal_iters: 341\td_loss:0.1259\tg_loss:4.0589\n",
      "Epoch: 70/100\titer: 0/5\ttotal_iters: 346\td_loss:0.1126\tg_loss:3.6933\n",
      "Epoch: 71/100\titer: 0/5\ttotal_iters: 351\td_loss:0.2755\tg_loss:5.6359\n",
      "Epoch: 72/100\titer: 0/5\ttotal_iters: 356\td_loss:0.1212\tg_loss:3.3531\n",
      "Epoch: 73/100\titer: 0/5\ttotal_iters: 361\td_loss:0.1746\tg_loss:2.4939\n",
      "Epoch: 74/100\titer: 0/5\ttotal_iters: 366\td_loss:0.2641\tg_loss:4.5714\n",
      "Epoch: 75/100\titer: 0/5\ttotal_iters: 371\td_loss:0.0996\tg_loss:3.814\n",
      "Epoch: 76/100\titer: 0/5\ttotal_iters: 376\td_loss:0.0769\tg_loss:3.7333\n",
      "Epoch: 77/100\titer: 0/5\ttotal_iters: 381\td_loss:0.0886\tg_loss:4.289\n",
      "Epoch: 78/100\titer: 0/5\ttotal_iters: 386\td_loss:0.0803\tg_loss:3.485\n",
      "Epoch: 79/100\titer: 0/5\ttotal_iters: 391\td_loss:0.1292\tg_loss:2.9421\n",
      "Epoch: 80/100\titer: 0/5\ttotal_iters: 396\td_loss:0.0714\tg_loss:3.7216\n",
      "Epoch: 81/100\titer: 0/5\ttotal_iters: 401\td_loss:0.0864\tg_loss:3.8278\n",
      "Epoch: 82/100\titer: 0/5\ttotal_iters: 406\td_loss:0.3036\tg_loss:5.0896\n",
      "Epoch: 83/100\titer: 0/5\ttotal_iters: 411\td_loss:0.072\tg_loss:3.8373\n",
      "Epoch: 84/100\titer: 0/5\ttotal_iters: 416\td_loss:0.0662\tg_loss:3.5731\n",
      "Epoch: 85/100\titer: 0/5\ttotal_iters: 421\td_loss:0.1003\tg_loss:4.086\n",
      "Epoch: 86/100\titer: 0/5\ttotal_iters: 426\td_loss:0.078\tg_loss:3.5999\n",
      "Epoch: 87/100\titer: 0/5\ttotal_iters: 431\td_loss:0.1114\tg_loss:2.8863\n",
      "Epoch: 88/100\titer: 0/5\ttotal_iters: 436\td_loss:0.0534\tg_loss:4.0071\n",
      "Epoch: 89/100\titer: 0/5\ttotal_iters: 441\td_loss:0.6514\tg_loss:7.8539\n",
      "Epoch: 90/100\titer: 0/5\ttotal_iters: 446\td_loss:0.0965\tg_loss:3.7617\n",
      "Epoch: 91/100\titer: 0/5\ttotal_iters: 451\td_loss:0.1584\tg_loss:3.6094\n",
      "Epoch: 92/100\titer: 0/5\ttotal_iters: 456\td_loss:0.1065\tg_loss:3.7593\n",
      "Epoch: 93/100\titer: 0/5\ttotal_iters: 461\td_loss:0.0578\tg_loss:3.8236\n",
      "Epoch: 94/100\titer: 0/5\ttotal_iters: 466\td_loss:0.0971\tg_loss:4.0621\n",
      "Epoch: 95/100\titer: 0/5\ttotal_iters: 471\td_loss:0.0586\tg_loss:3.7992\n",
      "Epoch: 96/100\titer: 0/5\ttotal_iters: 476\td_loss:0.1257\tg_loss:4.0286\n",
      "Epoch: 97/100\titer: 0/5\ttotal_iters: 481\td_loss:0.1128\tg_loss:4.4701\n",
      "Epoch: 98/100\titer: 0/5\ttotal_iters: 486\td_loss:0.1797\tg_loss:3.1142\n",
      "Epoch: 99/100\titer: 0/5\ttotal_iters: 491\td_loss:0.1519\tg_loss:5.9217\n",
      "Epoch: 100/100\titer: 0/5\ttotal_iters: 496\td_loss:0.0779\tg_loss:4.1219\n"
     ]
    }
   ],
   "source": [
    "# Training\n",
    "for epoch in range(EPOCHS):\n",
    "    gen.train()\n",
    "    dis.train()\n",
    "\n",
    "    for i, data in enumerate(data_loader):\n",
    "\n",
    "        total_iters += 1\n",
    "\n",
    "        x_real, x_label = data\n",
    "        batch_size = x_real.size(0)  # Tamanho do batch atual\n",
    "\n",
    "        # Ajustando o tamanho de z_fake para corresponder ao tamanho do batch atual\n",
    "        z_fake = torch.randn(batch_size, Z_DIM)\n",
    "        \n",
    "        real_label = torch.ones(batch_size)\n",
    "        fake_label = torch.zeros(batch_size)\n",
    "\n",
    "        if is_cuda:\n",
    "            x_real = x_real.cuda()\n",
    "            x_label = x_label.cuda()\n",
    "            z_fake = z_fake.cuda()\n",
    "                \n",
    "        # Generate fake data\n",
    "        x_fake = gen(z_fake, x_label)\n",
    "\n",
    "        # Train Discriminator\n",
    "        fake_out = dis(x_fake.detach(), x_label)\n",
    "        real_out = dis(x_real.detach(), x_label)\n",
    "        \n",
    "        d_loss = (loss_fn(fake_out, fake_label) + loss_fn(real_out, real_label)) / 2\n",
    "\n",
    "        d_opt.zero_grad()\n",
    "        d_loss.backward()\n",
    "        d_opt.step()\n",
    "\n",
    "        # Train Generator\n",
    "        fake_out = dis(x_fake, x_label)\n",
    "        g_loss = loss_fn(fake_out, real_label)\n",
    "\n",
    "        g_opt.zero_grad()\n",
    "        g_loss.backward()\n",
    "        g_opt.step()\n",
    "\n",
    "        if i % 50 == 0:\n",
    "            print(\"Epoch: \" + str(epoch + 1) + \"/\" + str(EPOCHS)\n",
    "                  + \"\\titer: \" + str(i) + \"/\" + str(max_iter)\n",
    "                  + \"\\ttotal_iters: \" + str(total_iters)\n",
    "                  + \"\\td_loss:\" + str(round(d_loss.item(), 4))\n",
    "                  + \"\\tg_loss:\" + str(round(g_loss.item(), 4))\n",
    "                  )\n",
    "\n",
    "    if (epoch + 1) % 5 == 0:\n",
    "        torch.save(gen.state_dict(), os.path.join(model_path, 'gen.pkl'))\n",
    "        torch.save(dis.state_dict(), os.path.join(model_path, 'dis.pkl'))\n",
    "\n",
    "        # generate_imgs(fixed_z, fixed_label, epoch=epoch + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_imgs_for_label_after_training(z, label, gen_model, epoch=0):\n",
    "    gen_model.eval()\n",
    "    \n",
    "    # Crie um tensor de labels com a label desejada\n",
    "    fixed_label = torch.full((z.size(0),), label, dtype=torch.long)\n",
    "    \n",
    "    # Gere as imagens com a label específica\n",
    "    with torch.no_grad():\n",
    "        fake_imgs = gen_model(z, fixed_label)\n",
    "    fake_imgs = (fake_imgs + 1) / 2\n",
    "    \n",
    "    # Crie a grade de imagens\n",
    "    fake_imgs_grid = vutils.make_grid(fake_imgs, normalize=False, nrow=IMGS_TO_DISPLAY_PER_CLASS)\n",
    "    \n",
    "    # Imprima a imagem gerada\n",
    "    print(fake_imgs_grid)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_imgs(fixed_z, fixed_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_to_generate = 8\n",
    "generate_imgs_for_label_after_training(fixed_z, label_to_generate, gen, epoch=epoch + 1)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
