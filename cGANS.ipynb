{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import optim\n",
    "import os\n",
    "import torchvision.utils as vutils\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import matplotlib as plt\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "from torchvision.models import inception_v3\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from scipy.stats import entropy\n",
    "from torchmetrics.image.fid import FrechetInceptionDistance\n",
    "\n",
    "#from google.colab import drive\n",
    "\n",
    "# Mount Google Drive\n",
    "#drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Arguments\n",
    "BATCH_SIZE = 64\n",
    "Z_DIM = 100\n",
    "LABEL_EMBED_SIZE = 5\n",
    "NUM_CLASSES = 10\n",
    "IMGS_TO_DISPLAY_PER_CLASS = 20\n",
    "LOAD_MODEL = False\n",
    "\n",
    "DB = 'SVHN'\n",
    "\n",
    "CHANNELS = 3\n",
    "EPOCHS = 25\n",
    "\n",
    "# Define the directory where your images are\n",
    "image_directory = 'TRAIN_AUG'\n",
    "\n",
    "# # Define the directory where your images are in Google Drive\n",
    "# image_directory = '/content/drive/My Drive/your_folder_name/TRAIN'\n",
    "\n",
    "# Directories for storing data, model and output samples\n",
    "model_path = os.path.join('./model', DB)\n",
    "os.makedirs(model_path, exist_ok=True)\n",
    "samples_path = os.path.join('./samples', DB)\n",
    "os.makedirs(samples_path, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset ImageFolder\n",
      "    Number of datapoints: 612\n",
      "    Root location: TRAIN_AUG\n",
      "    StandardTransform\n",
      "Transform: Compose(\n",
      "               Resize(size=[64, 64], interpolation=bilinear, max_size=None, antialias=warn)\n",
      "               ToTensor()\n",
      "               Normalize(mean=[0.5], std=[0.5])\n",
      "           )\n",
      "<torch.utils.data.dataloader.DataLoader object at 0x0000020E14BA5350>\n",
      "['12', '13', '24', '38', '39', '44', '46', '49', '50', '6']\n",
      "10\n"
     ]
    }
   ],
   "source": [
    "# Data loader\n",
    "\n",
    "# Define the directory where your images are\n",
    "image_directory = 'TRAIN_AUG'\n",
    "\n",
    "transform = transforms.Compose([transforms.Resize([64, 64]),\n",
    "                                transforms.ToTensor(),\n",
    "                                transforms.Normalize([0.5], [0.5])])\n",
    "\n",
    "\n",
    "train_dataset = datasets.ImageFolder(root=image_directory, transform=transform)\n",
    "\n",
    "print(train_dataset)\n",
    "\n",
    "\n",
    "data_loader = DataLoader(dataset=train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=4)\n",
    "\n",
    "print(data_loader)\n",
    "\n",
    "#show labels of the dataset\n",
    "\n",
    "print(train_dataset.classes)\n",
    "print(len(train_dataset.classes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Networks\n",
    "def conv_block(c_in, c_out, k_size=4, stride=2, pad=1, use_bn=True, transpose=False):\n",
    "    module = []\n",
    "    if transpose:\n",
    "        module.append(nn.ConvTranspose2d(c_in, c_out, k_size, stride, pad, bias=not use_bn))\n",
    "    else:\n",
    "        module.append(nn.Conv2d(c_in, c_out, k_size, stride, pad, bias=not use_bn))\n",
    "    if use_bn:\n",
    "        module.append(nn.BatchNorm2d(c_out))\n",
    "    return nn.Sequential(*module)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Generator(nn.Module):\n",
    "    def __init__(self, z_dim=10, num_classes=10, label_embed_size=5, channels=3, conv_dim=128):\n",
    "        super(Generator, self).__init__()\n",
    "        self.label_embedding = nn.Embedding(num_classes, label_embed_size)\n",
    "        self.tconv1 = conv_block(z_dim + label_embed_size, conv_dim * 8, pad=0, transpose=True)\n",
    "        self.tconv2 = conv_block(conv_dim * 8, conv_dim * 4, transpose=True)\n",
    "        self.tconv3 = conv_block(conv_dim * 4, conv_dim * 2, transpose=True)\n",
    "        self.tconv4 = conv_block(conv_dim * 2, conv_dim, transpose=True)\n",
    "        self.tconv5 = conv_block(conv_dim, channels, transpose=True, use_bn=False)\n",
    "\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d) or isinstance(m, nn.ConvTranspose2d):\n",
    "                nn.init.normal_(m.weight, 0.0, 0.02)\n",
    "\n",
    "            if isinstance(m, nn.BatchNorm2d):\n",
    "                nn.init.constant_(m.weight, 1)\n",
    "                nn.init.constant_(m.bias, 0)\n",
    "\n",
    "    def forward(self, x, label):\n",
    "        x = x.reshape([x.shape[0], -1, 1, 1])\n",
    "        label_embed = self.label_embedding(label)\n",
    "        label_embed = label_embed.reshape([label_embed.shape[0], -1, 1, 1])\n",
    "        x = torch.cat((x, label_embed), dim=1)\n",
    "        x = F.relu(self.tconv1(x))\n",
    "        x = F.relu(self.tconv2(x))\n",
    "        x = F.relu(self.tconv3(x))\n",
    "        x = F.tanh(self.tconv4(x))\n",
    "        x = torch.tanh(self.tconv5(x))\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Discriminator(nn.Module):\n",
    "    def __init__(self, num_classes=10, channels=3, conv_dim=128):\n",
    "        super(Discriminator, self).__init__()\n",
    "        self.image_size = 64\n",
    "        self.label_embedding = nn.Embedding(num_classes, self.image_size*self.image_size)\n",
    "        self.conv1 = conv_block(channels + 1, conv_dim, use_bn=False)\n",
    "        self.conv2 = conv_block(conv_dim, conv_dim * 2)\n",
    "        self.conv3 = conv_block(conv_dim * 2, conv_dim * 4)\n",
    "        self.conv4 = conv_block(conv_dim * 4, conv_dim * 8)\n",
    "        self.conv5 = conv_block(conv_dim * 8, 1, k_size=4, stride=1, pad=0, use_bn=False)\n",
    "\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                nn.init.normal_(m.weight, 0.0, 0.02)\n",
    "\n",
    "            if isinstance(m, nn.BatchNorm2d):\n",
    "                nn.init.constant_(m.weight, 1)\n",
    "                nn.init.constant_(m.bias, 0)\n",
    "\n",
    "    def forward(self, x, label):\n",
    "        alpha = 0.2\n",
    "        label_embed = self.label_embedding(label)\n",
    "        label_embed = label_embed.reshape([label_embed.shape[0], 1, self.image_size, self.image_size])\n",
    "        x = torch.cat((x, label_embed), dim=1)\n",
    "        x = F.leaky_relu(self.conv1(x), alpha)\n",
    "        x = F.leaky_relu(self.conv2(x), alpha)\n",
    "        x = F.leaky_relu(self.conv3(x), alpha)\n",
    "        x = F.leaky_relu(self.conv4(x), alpha)\n",
    "        x = torch.sigmoid(self.conv5(x))\n",
    "        return x.squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape from generator: torch.Size([1, 3, 64, 64])\n",
      "Output from discriminator: torch.Size([])\n"
     ]
    }
   ],
   "source": [
    "gen = Generator(z_dim=Z_DIM, num_classes=NUM_CLASSES, label_embed_size=LABEL_EMBED_SIZE, channels=CHANNELS)\n",
    "dis = Discriminator(num_classes=NUM_CLASSES, channels=CHANNELS)\n",
    "\n",
    "\n",
    "# Teste unitário para verificar a saída do gerador\n",
    "test_noise = torch.randn(1, Z_DIM)\n",
    "test_label = torch.LongTensor([1])  # Exemplo de label\n",
    "gen_output = gen(test_noise, test_label)\n",
    "print(\"Output shape from generator:\", gen_output.shape)\n",
    "\n",
    "# Teste unitário para o discriminador\n",
    "dis_output = dis(gen_output, test_label)\n",
    "print(\"Output from discriminator:\", dis_output.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------Generator------------------\n",
      "Generator(\n",
      "  (label_embedding): Embedding(10, 5)\n",
      "  (tconv1): Sequential(\n",
      "    (0): ConvTranspose2d(105, 1024, kernel_size=(4, 4), stride=(2, 2), bias=False)\n",
      "    (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  )\n",
      "  (tconv2): Sequential(\n",
      "    (0): ConvTranspose2d(1024, 512, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "    (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  )\n",
      "  (tconv3): Sequential(\n",
      "    (0): ConvTranspose2d(512, 256, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "    (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  )\n",
      "  (tconv4): Sequential(\n",
      "    (0): ConvTranspose2d(256, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "    (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  )\n",
      "  (tconv5): Sequential(\n",
      "    (0): ConvTranspose2d(128, 3, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
      "  )\n",
      ")\n",
      "------------------Discriminator------------------\n",
      "Discriminator(\n",
      "  (label_embedding): Embedding(10, 4096)\n",
      "  (conv1): Sequential(\n",
      "    (0): Conv2d(4, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
      "  )\n",
      "  (conv2): Sequential(\n",
      "    (0): Conv2d(128, 256, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "    (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  )\n",
      "  (conv3): Sequential(\n",
      "    (0): Conv2d(256, 512, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "    (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  )\n",
      "  (conv4): Sequential(\n",
      "    (0): Conv2d(512, 1024, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "    (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  )\n",
      "  (conv5): Sequential(\n",
      "    (0): Conv2d(1024, 1, kernel_size=(4, 4), stride=(1, 1))\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "gen = Generator(z_dim=Z_DIM, num_classes=NUM_CLASSES, label_embed_size=LABEL_EMBED_SIZE, channels=CHANNELS)\n",
    "dis = Discriminator(num_classes=NUM_CLASSES, channels=CHANNELS)\n",
    "\n",
    "# Load previous model   \n",
    "if LOAD_MODEL:\n",
    "    gen.load_state_dict(torch.load(os.path.join(model_path, 'gen.pkl')))\n",
    "    dis.load_state_dict(torch.load(os.path.join(model_path, 'dis.pkl')))\n",
    "    \n",
    "# Model Summary\n",
    "print(\"------------------Generator------------------\")\n",
    "print(gen)\n",
    "print(\"------------------Discriminator------------------\")\n",
    "print(dis)\n",
    "\n",
    "# Define Optimizers\n",
    "g_opt = optim.Adam(gen.parameters(), lr=0.0002, betas=(0.5, 0.999), weight_decay=2e-5)\n",
    "d_opt = optim.Adam(dis.parameters(), lr=0.0002, betas=(0.5, 0.999), weight_decay=2e-5)\n",
    "\n",
    "# Loss functions\n",
    "loss_fn = nn.BCELoss()\n",
    "\n",
    "# Fix images for viz\n",
    "fixed_z = torch.randn(IMGS_TO_DISPLAY_PER_CLASS*NUM_CLASSES, Z_DIM)\n",
    "fixed_label = torch.arange(0, NUM_CLASSES)\n",
    "fixed_label = torch.repeat_interleave(fixed_label, IMGS_TO_DISPLAY_PER_CLASS)\n",
    "\n",
    "\n",
    "# GPU Compatibility\n",
    "is_cuda = torch.cuda.is_available()\n",
    "if is_cuda:\n",
    "    gen, dis = gen.cuda(), dis.cuda()\n",
    "    real_label, fake_label = real_label.cuda(), fake_label.cuda()\n",
    "    fixed_z, fixed_label = fixed_z.cuda(), fixed_label.cuda()\n",
    "\n",
    "total_iters = 0\n",
    "max_iter = len(data_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/25\titer: 0/10\ttotal_iters: 1\td_loss:1.3147\tg_loss:19.1765\n",
      "Epoch: 2/25\titer: 0/10\ttotal_iters: 11\td_loss:1.4286\tg_loss:17.0472\n",
      "Epoch: 3/25\titer: 0/10\ttotal_iters: 21\td_loss:0.9969\tg_loss:10.3139\n",
      "Epoch: 4/25\titer: 0/10\ttotal_iters: 31\td_loss:2.0913\tg_loss:21.7794\n",
      "Epoch: 5/25\titer: 0/10\ttotal_iters: 41\td_loss:0.9762\tg_loss:20.8935\n",
      "Epoch: 6/25\titer: 0/10\ttotal_iters: 51\td_loss:0.7234\tg_loss:2.4083\n",
      "Epoch: 7/25\titer: 0/10\ttotal_iters: 61\td_loss:1.0293\tg_loss:5.3767\n",
      "Epoch: 8/25\titer: 0/10\ttotal_iters: 71\td_loss:0.5036\tg_loss:4.6542\n",
      "Epoch: 9/25\titer: 0/10\ttotal_iters: 81\td_loss:0.6548\tg_loss:6.4902\n",
      "Epoch: 10/25\titer: 0/10\ttotal_iters: 91\td_loss:0.6905\tg_loss:5.6028\n",
      "Epoch: 11/25\titer: 0/10\ttotal_iters: 101\td_loss:0.4424\tg_loss:3.6752\n",
      "Epoch: 12/25\titer: 0/10\ttotal_iters: 111\td_loss:0.4851\tg_loss:2.7592\n",
      "Epoch: 13/25\titer: 0/10\ttotal_iters: 121\td_loss:0.7697\tg_loss:4.4113\n",
      "Epoch: 14/25\titer: 0/10\ttotal_iters: 131\td_loss:0.6245\tg_loss:3.8086\n",
      "Epoch: 15/25\titer: 0/10\ttotal_iters: 141\td_loss:0.4688\tg_loss:3.6045\n",
      "Epoch: 16/25\titer: 0/10\ttotal_iters: 151\td_loss:0.442\tg_loss:2.1025\n",
      "Epoch: 17/25\titer: 0/10\ttotal_iters: 161\td_loss:0.5033\tg_loss:2.1295\n",
      "Epoch: 18/25\titer: 0/10\ttotal_iters: 171\td_loss:0.5153\tg_loss:3.1646\n",
      "Epoch: 19/25\titer: 0/10\ttotal_iters: 181\td_loss:0.4883\tg_loss:2.1338\n",
      "Epoch: 20/25\titer: 0/10\ttotal_iters: 191\td_loss:0.4735\tg_loss:1.3904\n",
      "Epoch: 21/25\titer: 0/10\ttotal_iters: 201\td_loss:0.4646\tg_loss:2.7418\n",
      "Epoch: 22/25\titer: 0/10\ttotal_iters: 211\td_loss:0.747\tg_loss:2.6664\n",
      "Epoch: 23/25\titer: 0/10\ttotal_iters: 221\td_loss:0.4204\tg_loss:2.9659\n",
      "Epoch: 24/25\titer: 0/10\ttotal_iters: 231\td_loss:0.4719\tg_loss:3.9367\n",
      "Epoch: 25/25\titer: 0/10\ttotal_iters: 241\td_loss:0.458\tg_loss:2.1927\n"
     ]
    }
   ],
   "source": [
    "# Training\n",
    "for epoch in range(EPOCHS):\n",
    "    gen.train()\n",
    "    dis.train()\n",
    "\n",
    "    for i, data in enumerate(data_loader):\n",
    "\n",
    "        total_iters += 1\n",
    "\n",
    "        x_real, x_label = data\n",
    "        batch_size = x_real.size(0)  # Tamanho do batch atual\n",
    "\n",
    "        # Ajustando o tamanho de z_fake para corresponder ao tamanho do batch atual\n",
    "        z_fake = torch.randn(batch_size, Z_DIM)\n",
    "        \n",
    "        real_label = torch.full((batch_size,), 0.9, dtype=torch.float, device=device)\n",
    "        fake_label = torch.full((batch_size,), 0.1, dtype=torch.float, device=device)\n",
    "\n",
    "        if is_cuda:\n",
    "            x_real = x_real.cuda()\n",
    "            x_label = x_label.cuda()\n",
    "            z_fake = z_fake.cuda()\n",
    "                \n",
    "        # Generate fake data\n",
    "        x_fake = gen(z_fake, x_label)\n",
    "\n",
    "        # Train Discriminator\n",
    "        fake_out = dis(x_fake.detach(), x_label)\n",
    "        real_out = dis(x_real.detach(), x_label)\n",
    "        \n",
    "        d_loss = (loss_fn(fake_out, fake_label) + loss_fn(real_out, real_label)) / 2\n",
    "\n",
    "        d_opt.zero_grad()\n",
    "        d_loss.backward()\n",
    "        d_opt.step()\n",
    "\n",
    "        # Train Generator\n",
    "        fake_out = dis(x_fake, x_label)\n",
    "        g_loss = loss_fn(fake_out, real_label)\n",
    "\n",
    "        g_opt.zero_grad()\n",
    "        g_loss.backward()\n",
    "        g_opt.step()\n",
    "\n",
    "        if i % 50 == 0:\n",
    "            print(\"Epoch: \" + str(epoch + 1) + \"/\" + str(EPOCHS)\n",
    "                  + \"\\titer: \" + str(i) + \"/\" + str(max_iter)\n",
    "                  + \"\\ttotal_iters: \" + str(total_iters)\n",
    "                  + \"\\td_loss:\" + str(round(d_loss.item(), 4))\n",
    "                  + \"\\tg_loss:\" + str(round(g_loss.item(), 4))\n",
    "                  )\n",
    "\n",
    "        # generate_imgs(fixed_z, fixed_label, epoch=epoch + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Função para calcular Inception Score\n",
    "def inception_score(imgs, device, batch_size=32, resize=True, splits=10):\n",
    "    N = len(imgs)\n",
    "    \n",
    "    # Inception v3 model\n",
    "    inception_model = inception_v3(pretrained=True, transform_input=False).to(device)\n",
    "    inception_model.eval()\n",
    "    \n",
    "    def get_pred(x):\n",
    "        if resize:\n",
    "            x = F.interpolate(x, size=(299, 299), mode='bilinear', align_corners=False)\n",
    "        x = inception_model(x)\n",
    "        return F.softmax(x, dim=1).data.cpu().numpy()\n",
    "\n",
    "    preds = np.zeros((N, 1000))\n",
    "\n",
    "    dataloader = DataLoader(TensorDataset(imgs), batch_size=batch_size)\n",
    "\n",
    "    for i, batch in enumerate(dataloader, 0):\n",
    "        batch = batch[0].to(device)\n",
    "        batch_size_i = batch.size()[0]\n",
    "\n",
    "        preds[i*batch_size:i*batch_size + batch_size_i] = get_pred(batch)\n",
    "\n",
    "    split_scores = []\n",
    "\n",
    "    for k in range(splits):\n",
    "        part = preds[k * (N // splits): (k+1) * (N // splits), :]\n",
    "        py = np.mean(part, axis=0)\n",
    "        scores = []\n",
    "        for i in range(part.shape[0]):\n",
    "            pyx = part[i, :]\n",
    "            scores.append(entropy(pyx, py))\n",
    "        split_scores.append(np.exp(np.mean(scores)))\n",
    "\n",
    "    return np.mean(split_scores), np.std(split_scores)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inception Score: 1.7067752390931994 ± 0.22679971722772158\n",
      "FID Score: 312.4044494628906\n"
     ]
    }
   ],
   "source": [
    "# Gerar imagens usando o gerador treinado\n",
    "def generate_images(generator, num_images, z_dim, num_classes, device):\n",
    "    generator.eval()\n",
    "    z = torch.randn(num_images, z_dim).to(device)\n",
    "    labels = torch.randint(0, num_classes, (num_images,)).to(device)\n",
    "    with torch.no_grad():\n",
    "        images = generator(z, labels)\n",
    "    return images\n",
    "\n",
    "# Configurações\n",
    "num_images = 100  # Número de imagens a serem geradas\n",
    "z_dim = 100\n",
    "num_classes = 10\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Gerar as imagens\n",
    "images = generate_images(gen, num_images, z_dim, num_classes, device)\n",
    "\n",
    "# Calcular o Inception Score\n",
    "mean, std = inception_score(images, device)\n",
    "print(f\"Inception Score: {mean} ± {std}\")\n",
    "\n",
    "# Carregar imagens reais do DataLoader\n",
    "real_images = []\n",
    "for i, (data, _) in enumerate(data_loader):\n",
    "    real_images.append(data)\n",
    "    if len(real_images) * data.shape[0] >= num_images:\n",
    "        break\n",
    "\n",
    "real_images = torch.cat(real_images, dim=0)[:num_images] \n",
    "\n",
    "# Converta as imagens para uint8\n",
    "real_images = (real_images * 255).byte()\n",
    "generated_images = (images * 255).byte()\n",
    "\n",
    "# Mover para o dispositivo (GPU/CPU)\n",
    "real_images = real_images.to(device)\n",
    "generated_images = generated_images.to(device)\n",
    "\n",
    "# Preparar o objeto FID\n",
    "fid = FrechetInceptionDistance(feature=2048).to(device)\n",
    "\n",
    "# Calcular FID\n",
    "fid.update(real_images, real=True)\n",
    "fid.update(generated_images, real=False)\n",
    "\n",
    "fid_score = fid.compute()\n",
    "print(f'FID Score: {fid_score.item()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save the model for later use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(gen.state_dict(), os.path.join(model_path, 'gen.pkl'))\n",
    "torch.save(dis.state_dict(), os.path.join(model_path, 'dis.pkl'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_imgs_for_all_labels(z, gen, num_labels, epoch=0):\n",
    "    gen.eval()\n",
    "    plt.figure(figsize=(15, 15))  # Ajusta o tamanho da figura para acomodar várias subfiguras\n",
    "\n",
    "    for label in range(num_labels):\n",
    "        fixed_label = torch.full((z.size(0),), label, dtype=torch.long)\n",
    "        with torch.no_grad():\n",
    "            fake_imgs = gen(z, fixed_label)\n",
    "        fake_imgs = (fake_imgs + 1) / 2  # Normaliza as imagens para o intervalo [0, 1]\n",
    "        fake_imgs_grid = vutils.make_grid(fake_imgs, normalize=False, nrow=IMGS_TO_DISPLAY_PER_CLASS)\n",
    "\n",
    "        # Converter tensor de imagens para um formato que o matplotlib possa exibir\n",
    "        np_img = fake_imgs_grid.permute(1, 2, 0).numpy()  # Reordenar as dimensões para HxWxC\n",
    "\n",
    "        # Cria uma subfigura para cada label\n",
    "        ax = plt.subplot(num_labels//2 + num_labels%2, 2, label + 1)  # Ajusta o layout da subplot\n",
    "        ax.imshow(np_img)\n",
    "        ax.set_title(f'Label {label}')\n",
    "        ax.axis('off')  # Desativa os eixos\n",
    "\n",
    "    plt.show()  # Mostra a imagem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_img_for_label_after_training(z, label, gen_model, epoch=0):\n",
    "    gen_model.eval()\n",
    "\n",
    "    # Cria um tensor de labels com a label desejada\n",
    "    fixed_label = torch.full((1,), label, dtype=torch.long)  # Mudança para gerar apenas uma imagem\n",
    "    \n",
    "    # Gera a imagem com a label específica\n",
    "    with torch.no_grad():\n",
    "        fake_img = gen_model(z[0:1], fixed_label)  # Seleciona apenas um z para geração\n",
    "    fake_img = (fake_img + 1) / 2  # Normalização para adequar ao matplotlib\n",
    "    \n",
    "    # Converter tensor de imagens para um formato que o matplotlib possa exibir\n",
    "    np_img = fake_img.squeeze(0).permute(1, 2, 0).numpy()  # Remove batch dim e reordena para HxWxC\n",
    "    plt.figure(figsize=(1, 1))  # Define o tamanho da figura\n",
    "    plt.imshow(np_img)\n",
    "    plt.axis('off')  # Desativa os eixos\n",
    "    plt.show()  # Mostra a imagem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'torch' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m z \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241m.\u001b[39mrandn(\u001b[38;5;241m10\u001b[39m, \u001b[38;5;241m100\u001b[39m)\n\u001b[0;32m      3\u001b[0m generate_imgs_for_all_labels(z, gen, \u001b[38;5;241m10\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'torch' is not defined"
     ]
    }
   ],
   "source": [
    "z = torch.randn(10, 100)\n",
    "\n",
    "generate_imgs_for_all_labels(z, gen, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 100x100 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "label_to_generate = 0\n",
    "generate_img_for_label_after_training(fixed_z, label_to_generate, gen, epoch=epoch + 1)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
