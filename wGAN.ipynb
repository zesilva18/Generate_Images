{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import optim\n",
    "import os\n",
    "import torchvision.utils as vutils\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import matplotlib as plt\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "from torchvision.models import inception_v3\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from scipy.stats import entropy\n",
    "from torchmetrics.image.fid import FrechetInceptionDistance\n",
    "from torch.autograd import Variable\n",
    "from torch import autograd\n",
    "from tqdm import tqdm\n",
    "\n",
    "print(torch.cuda.is_available())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the directory where your images are\n",
    "train_dataset_path = 'data-students\\\\TRAIN'\n",
    "\n",
    "IMG_WIDTH = 75\n",
    "IMG_HEIGHT = 75\n",
    "BATCH_SIZE = 64\n",
    "NUM_CLASSES = 10\n",
    "\n",
    "\n",
    "transform = transforms.Compose([transforms.Resize([75, 75]),\n",
    "                                transforms.ToTensor(),\n",
    "                                transforms.Normalize([0.5], [0.5])])\n",
    "\n",
    "\n",
    "train_dataset = datasets.ImageFolder(root=train_dataset_path, transform=transform)\n",
    "\n",
    "train_dataset_loader = DataLoader(dataset=train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=4)\n",
    "\n",
    "print(train_dataset_loader)\n",
    "\n",
    "#show labels of the dataset\n",
    "\n",
    "print(train_dataset.classes)\n",
    "print(len(train_dataset.classes))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Descriminator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Discriminator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Discriminator, self).__init__()\n",
    "\n",
    "        def discriminator_block(in_filters, out_filters, kernel_size, stride, padding):\n",
    "            block = [\n",
    "                nn.Conv2d(in_filters, out_filters, kernel_size=kernel_size, stride=stride, padding=padding), \n",
    "                nn.InstanceNorm2d(out_filters, 0.8),\n",
    "                nn.LeakyReLU(0.2, inplace=True)\n",
    "                ]\n",
    "\n",
    "            return torch.nn.Sequential(*block)\n",
    "        \n",
    "        n = 128\n",
    "        self.db_1 = discriminator_block(4, n, 3, 1, 0)\n",
    "        self.db_2 = discriminator_block(n, 2*n, 5, 2, 1)\n",
    "        self.db_3 = discriminator_block(2*n, 4*n, 4, 2, 1)\n",
    "        self.db_4 = discriminator_block(4*n, 8*n, 4, 2, 0)\n",
    "        self.adv_layer = nn.Sequential(nn.Conv2d(8*n, 1, 8, 1, 0))\n",
    "\n",
    "        # Embedding for the label\n",
    "        self.embedding = nn.Embedding(10, 24*24)\n",
    "        self.transpose_embedding = nn.ConvTranspose2d(1, 1, 6, 3, 0)\n",
    "\n",
    "    def forward(self, img, label):\n",
    "        l = self.embedding(label)\n",
    "        l = l.view(l.size(0), 1, 24, 24)\n",
    "        l = self.transpose_embedding(l)\n",
    "        x = torch.cat([img, l], 1)\n",
    "        x = self.db_1(x)\n",
    "        x = self.db_2(x)\n",
    "        x = self.db_3(x)\n",
    "        x = self.db_4(x)\n",
    "        y = self.adv_layer(x)\n",
    "\n",
    "        return y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Generator(torch.nn.Module):\n",
    "    def __init__(self, *args, **kwargs) -> None:\n",
    "        super().__init__(*args, **kwargs)\n",
    "\n",
    "        self.channels = 3\n",
    "        n = 128\n",
    "\n",
    "        def generator_block(in_filters, out_filters, kernel_size, stride, padding):\n",
    "            block = [\n",
    "                nn.ConvTranspose2d(in_filters, out_filters, kernel_size=kernel_size, stride=stride, padding=padding), \n",
    "                nn.BatchNorm2d(out_filters, 0.8),\n",
    "                nn.ReLU(True)\n",
    "                ]\n",
    "\n",
    "            return torch.nn.Sequential(*block)\n",
    "        \n",
    "        self.gb_1 = generator_block(100+256, 16*n, 4, 1, 0)\n",
    "        self.gb_2 = generator_block(16*n, 8*n, 4, 2, 1)\n",
    "        self.gb_3 = generator_block(8*n, 4*n, 4, 2, 0)\n",
    "        self.gb_4 = generator_block(4*n, 2*n, 4, 2, 1)\n",
    "        self.gb_5 = generator_block(2*n, n, 5, 2, 1)\n",
    "        self.projection_layer = torch.nn.Sequential(\n",
    "            nn.ConvTranspose2d(\n",
    "                in_channels=n, \n",
    "                out_channels=self.channels, \n",
    "                kernel_size=3, \n",
    "                stride=1, \n",
    "                padding=0\n",
    "                ),\n",
    "            nn.Tanh()\n",
    "        )\n",
    "\n",
    "        self.embedding = nn.Embedding(10, 256)\n",
    "\n",
    "    def forward(self, noise, label):\n",
    "        l = self.embedding(label)\n",
    "        l = l.view(l.size(0), l.size(1), 1, 1)\n",
    "        x = torch.cat([noise, l], 1)\n",
    "        x = self.gb_1(x)\n",
    "        x = self.gb_2(x)\n",
    "        x = self.gb_3(x)\n",
    "        x = self.gb_4(x)\n",
    "        x = self.gb_5(x)\n",
    "        y = self.projection_layer(x)\n",
    "        return y\n",
    "    \n",
    "    def make_random_noise_vector(self, batch_size):\n",
    "        return torch.randn(batch_size, 100, 1, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## WGAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class WGAN(torch.nn.Module):\n",
    "    def __init__(self, *args, **kwargs) -> None:\n",
    "        \"\"\"\n",
    "        WGAN or Wasserstein GAN model is a type of GAN model that uses the Wasserstein distance to train the generator and discriminator. It improves the stability of the GAN model and helps in generating better quality images. In this architecture the discriminator has a linear output activation, that represents the quality of the generated images instead of a simple classification. Has the quality tends to improve gradient penalty is used to enforce the Lipschitz constraint on the discriminator. This helps in generating better quality images and improves the stability of the GAN model.\n",
    "\n",
    "        A conditional Deep Convolutional GAN (cDCGAN) architecture is used for the generator and discriminator. The generator uses a series of transpose convolutional layers to generate images from a random noise vector and a label. The discriminator uses a series of convolutional layers to classify the images as real or fake. The discriminator also uses an embedding layer to embed the class label into the image. This helps in generating images for a specific class.\n",
    "        \"\"\"\n",
    "        super().__init__(*args, **kwargs)\n",
    "        \n",
    "        self.generator = Generator()\n",
    "        self.discriminator = Discriminator()\n",
    "\n",
    "        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "        self.generator = self.generator.to(self.device)\n",
    "        self.discriminator = self.discriminator.to(self.device)\n",
    "\n",
    "    def forward(self, label):\n",
    "        noise = self.generator.make_random_noise_vector(1).to(self.device)\n",
    "        fake_image = self.generator(noise, label)\n",
    "        fake_image = fake_image.cpu().detach().numpy()\n",
    "        fake_image = (fake_image + 1) / 2\n",
    "        return fake_image.transpose(0, 2, 3, 1)[0]\n",
    "\n",
    "    def gradient_penalty(self, real_images, fake_images, label):\n",
    "        batch_size = real_images.size(0)\n",
    "        eta = torch.FloatTensor(batch_size, 1, 1, 1).uniform_(0, 1).to(self.device)\n",
    "        eta = eta.expand(batch_size, real_images.size(1), real_images.size(2), real_images.size(3))\n",
    "\n",
    "        interpolated = eta * real_images + ((1 - eta) * fake_images)\n",
    "        interpolated = interpolated.to(self.device)\n",
    "\n",
    "        # define it to calculate gradient\n",
    "        interpolated = Variable(interpolated, requires_grad=True).to(self.device)\n",
    "\n",
    "        # calculate probability of interpolated examples\n",
    "        prob_interpolated = self.discriminator(interpolated, label).to(self.device)\n",
    "\n",
    "        # calculate gradients of probabilities with respect to examples\n",
    "        gradients = autograd.grad(\n",
    "            outputs=prob_interpolated,\n",
    "            inputs=interpolated,\n",
    "            grad_outputs=torch.ones(prob_interpolated.size()).to(self.device),\n",
    "            create_graph=True,\n",
    "            retain_graph=True)[0].to(self.device)\n",
    "\n",
    "        # flatten the gradients to it calculates norm batchwise\n",
    "        gradients = gradients.view(gradients.size(0), -1)\n",
    "        \n",
    "        grad_penalty = ((gradients.norm(2, dim=1) - 1) ** 2).mean()\n",
    "        return grad_penalty\n",
    "    \n",
    "    def train(self, dataset, n_epochs: int, batch_size: int, n_critic: int, lr_generator: float, lr_discriminator: float):\n",
    "        \"\"\"\n",
    "        Train the WGAN\n",
    "        \"\"\"\n",
    "        # Define the optimizer\n",
    "        optimizer_discriminator = torch.optim.AdamW(self.discriminator.parameters(), lr=lr_discriminator, betas=(0.5, 0.999))\n",
    "        optimizer_generator = torch.optim.AdamW(self.generator.parameters(), lr=lr_generator, betas=(0.5, 0.999))\n",
    "\n",
    "        for epoch in range(n_epochs):\n",
    "            pbar = tqdm(enumerate(dataset), total=len(dataset))\n",
    "            for i, (imgs, label) in enumerate(dataset):\n",
    "                label = label.to(self.device)\n",
    "                imgs = imgs.to(self.device)\n",
    "    \n",
    "                batch_size = imgs.shape[0]\n",
    "\n",
    "                for p in self.discriminator.parameters():\n",
    "                        p.requires_grad = True\n",
    "\n",
    "                # Train the discriminator\n",
    "                for _ in range(n_critic):\n",
    "                    self.discriminator.zero_grad()\n",
    "\n",
    "                    # Generate a batch of images\n",
    "                    noise = self.generator.make_random_noise_vector(batch_size).to(self.device)\n",
    "\n",
    "                    # Loss for real images\n",
    "                    d_real_loss = self.discriminator(imgs, label)\n",
    "                    d_real_loss = d_real_loss.mean()\n",
    "\n",
    "                    # Loss for fake images\n",
    "                    fake_images = self.generator(noise, label).detach()\n",
    "                    d_fake_loss = self.discriminator(fake_images, label)\n",
    "                    d_fake_loss = d_fake_loss.mean()\n",
    "\n",
    "                    w_d = d_real_loss - d_fake_loss\n",
    "                    # Gradient penalty\n",
    "                    gradient_penalty = self.gradient_penalty(imgs.data, fake_images.data, label)\n",
    "\n",
    "                    # Total loss\n",
    "                    d_loss = -w_d + gradient_penalty * 5\n",
    "                    d_loss.backward()\n",
    "                    optimizer_discriminator.step()\n",
    "                \n",
    "                # Train the generator\n",
    "                for p in self.discriminator.parameters():\n",
    "                    p.requires_grad = False\n",
    "\n",
    "                self.generator.zero_grad()\n",
    "\n",
    "                noise = self.generator.make_random_noise_vector(batch_size).to(self.device)\n",
    "\n",
    "                fake_images = self.generator(noise, label)\n",
    "                g_loss = self.discriminator(fake_images, label)\n",
    "                g_loss = -g_loss.mean()\n",
    "                g_loss.backward()\n",
    "                g_cost = -g_loss\n",
    "                optimizer_generator.step()\n",
    "                \n",
    "                print(f'Epoch: {epoch}, Discriminator Loss: {d_loss}, Generator Loss: {g_cost}')\n",
    "                pbar.set_description(f'Epoch: {epoch}, Batch: {i}, Discriminator Loss: {d_loss}, Generator Loss: {g_cost}')\n",
    "\n",
    "                l = torch.tensor([0]).to(self.device)\n",
    "                image = self.forward(l)\n",
    "                plt.imshow(image)\n",
    "                plt.savefig(f'output/output.png')\n",
    "\n",
    "            if epoch % 10 == 0:\n",
    "                noise = self.generator.make_random_noise_vector(25).to(self.device)\n",
    "                label = torch.randint(0, 10, (25,)).to(self.device)\n",
    "                print(label)\n",
    "                fake_images = self.generator(noise, label)\n",
    "                fake_images = fake_images.cpu().detach().numpy()\n",
    "                fig, axes = plt.subplots(5, 5, figsize=(10, 10))\n",
    "                for i, ax in enumerate(axes.flat):\n",
    "                    fake_images[i] = (fake_images[i] + 1) / 2\n",
    "                    ax.imshow(fake_images[i].transpose(1, 2, 0))\n",
    "                    ax.axis('off')\n",
    "                    ax.set_title(f'Label: {label[i]}')\n",
    "                plt.savefig(f'output/epoch_{epoch}.png')\n",
    "                self.save(f'output/epoch_{epoch}', save_generator=True, save_discriminator=True)\n",
    "\n",
    "    def save(self, path, save_generator=True, save_discriminator=True):\n",
    "        if save_generator:\n",
    "            torch.save(self.generator.state_dict(), path + '_generator.pth')\n",
    "        if save_discriminator:\n",
    "            torch.save(self.discriminator.state_dict(), path + '_discriminator.pth')\n",
    "\n",
    "    def load(self, path, load_generator=True, load_discriminator=True):\n",
    "        if load_generator:\n",
    "            self.generator.load_state_dict(torch.load(path + '_generator.pth'))\n",
    "        if load_discriminator:\n",
    "            self.discriminator.load_state_dict(torch.load(path + '_discriminator.pth'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wgan = WGAN()\n",
    "\n",
    "wgan.train(train_dataset_loader, n_epochs=10, batch_size=BATCH_SIZE, n_critic=5, lr_generator=1e-4, lr_discriminator=1e-4)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
