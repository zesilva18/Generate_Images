{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import de bibliotecas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image  # Install Pillow -> conda install anaconda::pillow or pip install pillow\n",
    "import os\n",
    "from skimage.io import imread, imshow  # Install scikit-image -> conda install scikit-image or pip install scikit-image\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import numpy as np\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score, f1_score\n",
    "import pandas as pd\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "from torch import autograd\n",
    "from torch.utils.data import Dataset, DataLoader, Subset\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tqdm import tqdm\n",
    "from time import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Settings and Paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# General Settings\n",
    "IMG_WIDTH = 75\n",
    "IMG_HEIGHT = 75\n",
    "BATCH_SIZE = 16\n",
    "\n",
    "# Paths\n",
    "train_dataset_path = 'data-students/TRAIN/'\n",
    "test_dataset_path = 'data-students/TEST'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define the Discriminator Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class Discriminator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Discriminator, self).__init__()\n",
    "\n",
    "        n = 128\n",
    "        \n",
    "        # Define the discriminator blocks\n",
    "        self.db_1 = self._discriminator_block(4, n, 3, 1, 0)\n",
    "        self.db_2 = self._discriminator_block(n, 2 * n, 5, 2, 1)\n",
    "        self.db_3 = self._discriminator_block(2 * n, 4 * n, 4, 2, 1)\n",
    "        self.db_4 = self._discriminator_block(4 * n, 8 * n, 4, 2, 0)\n",
    "        \n",
    "        # Final layer to output a single value\n",
    "        self.adv_layer = nn.Conv2d(8 * n, 1, 8, 1, 0)\n",
    "\n",
    "        # Embedding for the label\n",
    "        self.embedding = nn.Embedding(10, 24 * 24)\n",
    "        self.transpose_embedding = nn.ConvTranspose2d(1, 1, 6, 3, 0)\n",
    "\n",
    "    def _discriminator_block(self, in_filters, out_filters, kernel_size, stride, padding):\n",
    "        \"\"\"Creates a block for the discriminator with Conv2d, InstanceNorm2d, and LeakyReLU.\"\"\"\n",
    "        block = [\n",
    "            nn.Conv2d(in_filters, out_filters, kernel_size=kernel_size, stride=stride, padding=padding), \n",
    "            nn.InstanceNorm2d(out_filters, 0.8),\n",
    "            nn.LeakyReLU(0.2, inplace=True)\n",
    "        ]\n",
    "        return nn.Sequential(*block)\n",
    "\n",
    "    def forward(self, img, label):\n",
    "        # Embed the label and reshape it\n",
    "        l = self.embedding(label)\n",
    "        l = l.view(l.size(0), 1, 24, 24)\n",
    "        l = self.transpose_embedding(l)\n",
    "        \n",
    "        # Concatenate the image and label embedding\n",
    "        x = torch.cat([img, l], 1)\n",
    "        \n",
    "        # Apply discriminator blocks\n",
    "        x = self.db_1(x)\n",
    "        x = self.db_2(x)\n",
    "        x = self.db_3(x)\n",
    "        x = self.db_4(x)\n",
    "        \n",
    "        # Apply the final layer\n",
    "        y = self.adv_layer(x)\n",
    "        \n",
    "        return y\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define the Generator Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Generator(nn.Module):\n",
    "    def __init__(self, *args, **kwargs) -> None:\n",
    "        super().__init__(*args, **kwargs)\n",
    "\n",
    "        self.channels = 3\n",
    "        n = 128\n",
    "\n",
    "        # Define the generator blocks\n",
    "        self.gb_1 = self._generator_block(100 + 256, 16 * n, 4, 1, 0)\n",
    "        self.gb_2 = self._generator_block(16 * n, 8 * n, 4, 2, 1)\n",
    "        self.gb_3 = self._generator_block(8 * n, 4 * n, 4, 2, 0)\n",
    "        self.gb_4 = self._generator_block(4 * n, 2 * n, 4, 2, 1)\n",
    "        self.gb_5 = self._generator_block(2 * n, n, 5, 2, 1)\n",
    "        \n",
    "        # Final layer to output the image\n",
    "        self.projection_layer = nn.Sequential(\n",
    "            nn.ConvTranspose2d(\n",
    "                in_channels=n, \n",
    "                out_channels=self.channels, \n",
    "                kernel_size=3, \n",
    "                stride=1, \n",
    "                padding=0\n",
    "            ),\n",
    "            nn.Tanh()\n",
    "        )\n",
    "\n",
    "        # Embedding for the label\n",
    "        self.embedding = nn.Embedding(10, 256)\n",
    "\n",
    "    def _generator_block(self, in_filters, out_filters, kernel_size, stride, padding):\n",
    "        \"\"\"Creates a block for the generator with ConvTranspose2d, BatchNorm2d, and ReLU.\"\"\"\n",
    "        block = [\n",
    "            nn.ConvTranspose2d(in_filters, out_filters, kernel_size=kernel_size, stride=stride, padding=padding), \n",
    "            nn.BatchNorm2d(out_filters, 0.8),\n",
    "            nn.ReLU(True)\n",
    "        ]\n",
    "        return nn.Sequential(*block)\n",
    "\n",
    "    def forward(self, noise, label):\n",
    "        # Embed the label and reshape it\n",
    "        l = self.embedding(label)\n",
    "        l = l.view(l.size(0), l.size(1), 1, 1)\n",
    "        \n",
    "        # Concatenate the noise and label embedding\n",
    "        x = torch.cat([noise, l], 1)\n",
    "        \n",
    "        # Apply generator blocks\n",
    "        x = self.gb_1(x)\n",
    "        x = self.gb_2(x)\n",
    "        x = self.gb_3(x)\n",
    "        x = self.gb_4(x)\n",
    "        x = self.gb_5(x)\n",
    "        \n",
    "        # Apply the final projection layer\n",
    "        y = self.projection_layer(x)\n",
    "        \n",
    "        return y\n",
    "    \n",
    "    def make_random_noise_vector(self, batch_size):\n",
    "        \"\"\"Generates a random noise vector.\"\"\"\n",
    "        return torch.randn(batch_size, 100, 1, 1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define the WGAN class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class WGAN(nn.Module):\n",
    "    def __init__(self, *args, **kwargs) -> None:\n",
    "        super().__init__(*args, **kwargs)\n",
    "        \n",
    "        self.generator = Generator()\n",
    "        self.discriminator = Discriminator()\n",
    "\n",
    "        self.generator = self.generator.to('cuda')\n",
    "        self.discriminator = self.discriminator.to('cuda')\n",
    "    \n",
    "    def forward(self, label):\n",
    "        noise = self.generator.make_random_noise_vector(1).to('cuda')\n",
    "        fake_image = self.generator(noise, label)\n",
    "        fake_image = fake_image.cpu().detach().numpy()\n",
    "        fake_image = (fake_image + 1) / 2  # Normalize to [0, 1]\n",
    "        return fake_image.transpose(0, 2, 3, 1)[0]\n",
    "\n",
    "    def gradient_penalty(self, real_images, fake_images, label):\n",
    "        batch_size = real_images.size(0)\n",
    "        eta = torch.FloatTensor(batch_size, 1, 1, 1).uniform_(0, 1).to('cuda')\n",
    "        eta = eta.expand_as(real_images)\n",
    "\n",
    "        interpolated = eta * real_images + ((1 - eta) * fake_images)\n",
    "        interpolated = interpolated.to('cuda')\n",
    "        interpolated = Variable(interpolated, requires_grad=True)\n",
    "\n",
    "        # Calculate probability of interpolated examples\n",
    "        prob_interpolated = self.discriminator(interpolated, label)\n",
    "\n",
    "        # Calculate gradients of probabilities with respect to examples\n",
    "        gradients = autograd.grad(\n",
    "            outputs=prob_interpolated,\n",
    "            inputs=interpolated,\n",
    "            grad_outputs=torch.ones(prob_interpolated.size()).to('cuda'),\n",
    "            create_graph=True,\n",
    "            retain_graph=True\n",
    "        )[0]\n",
    "\n",
    "        # Flatten the gradients to calculate norm batchwise\n",
    "        gradients = gradients.view(batch_size, -1)\n",
    "        grad_penalty = ((gradients.norm(2, dim=1) - 1) ** 2).mean()\n",
    "        return grad_penalty\n",
    "\n",
    "    def train(self, dataset, n_epochs: int, batch_size: int, n_critic: int, lr_generator: float, lr_discriminator: float):\n",
    "\n",
    "        for epoch in range(n_epochs):\n",
    "            pbar = tqdm(enumerate(dataset), total=len(dataset))\n",
    "            for i, (imgs, label) in pbar:\n",
    "                label = label.to('cuda')\n",
    "                imgs = imgs.to('cuda')\n",
    "                batch_size = imgs.size(0)\n",
    "\n",
    "                for p in self.discriminator.parameters():\n",
    "                    p.requires_grad = True\n",
    "\n",
    "                # Train the discriminator\n",
    "                for _ in range(n_critic):\n",
    "                    self.discriminator.zero_grad()\n",
    "\n",
    "                    # Generate a batch of images\n",
    "                    noise = self.generator.make_random_noise_vector(batch_size).to('cuda')\n",
    "\n",
    "                    # Loss for real images\n",
    "                    d_real_loss = self.discriminator(imgs, label).mean()\n",
    "\n",
    "                    # Loss for fake images\n",
    "                    fake_images = self.generator(noise, label).detach()\n",
    "                    d_fake_loss = self.discriminator(fake_images, label).mean()\n",
    "\n",
    "                    w_d = d_real_loss - d_fake_loss\n",
    "                    # Gradient penalty\n",
    "                    gradient_penalty = self.gradient_penalty(imgs.data, fake_images.data, label)\n",
    "\n",
    "                    # Total loss\n",
    "                    d_loss = -w_d + gradient_penalty * 5\n",
    "                    d_loss.backward()\n",
    "                    optimizer_discriminator.step()\n",
    "                \n",
    "                # Train the generator\n",
    "                for p in self.discriminator.parameters():\n",
    "                    p.requires_grad = False\n",
    "\n",
    "                self.generator.zero_grad()\n",
    "\n",
    "                noise = self.generator.make_random_noise_vector(batch_size).to('cuda')\n",
    "                fake_images = self.generator(noise, label)\n",
    "                g_loss = self.discriminator(fake_images, label).mean()\n",
    "                g_loss = -g_loss\n",
    "                g_loss.backward()\n",
    "                optimizer_generator.step()\n",
    "\n",
    "                pbar.set_description(f'Epoch: {epoch}, Batch: {i}, Discriminator Loss: {d_loss:.4f}, Generator Loss: {g_loss:.4f}')\n",
    "\n",
    "                if i % 100 == 0:  # Save output every 100 batches\n",
    "                    l = torch.tensor([0]).to('cuda')\n",
    "                    image = self.forward(l)\n",
    "                    plt.imshow(image)\n",
    "                    plt.savefig(f'output/output_epoch_{epoch}_batch_{i}.png')\n",
    "\n",
    "            if epoch % 10 == 0:\n",
    "                self.save_images(epoch)\n",
    "                self.save_models(epoch)\n",
    "\n",
    "    def save_images(self, epoch):\n",
    "        noise = self.generator.make_random_noise_vector(25).to('cuda')\n",
    "        labels = torch.randint(0, 10, (25,)).to('cuda')\n",
    "        fake_images = self.generator(noise, labels).cpu().detach().numpy()\n",
    "        fake_images = (fake_images + 1) / 2  # Normalize to [0, 1]\n",
    "\n",
    "        fig, axes = plt.subplots(5, 5, figsize=(10, 10))\n",
    "        for i, ax in enumerate(axes.flat):\n",
    "            ax.imshow(fake_images[i].transpose(1, 2, 0))\n",
    "            ax.axis('off')\n",
    "            ax.set_title(f'Label: {labels[i].item()}')\n",
    "        plt.savefig(f'output/epoch_{epoch}.png')\n",
    "\n",
    "    def save_models(self, epoch):\n",
    "        self.save(f'output/epoch_{epoch}', save_generator=True, save_discriminator=True)\n",
    "\n",
    "    def save(self, path, save_generator=True, save_discriminator=True):\n",
    "        if save_generator:\n",
    "            torch.save(self.generator.state_dict(), path + '_generator.pth')\n",
    "        if save_discriminator:\n",
    "            torch.save(self.discriminator.state_dict(), path + '_discriminator.pth')\n",
    "\n",
    "    def load(self, path, load_generator=True, load_discriminator=True):\n",
    "        if load_generator:\n",
    "            self.generator.load_state_dict(torch.load(path + '_generator.pth'))\n",
    "        if load_discriminator:\n",
    "            self.discriminator.load_state_dict(torch.load(path + '_discriminator.pth'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define paths and settings\n",
    "train_dataset_path = 'data-students/TRAIN/'\n",
    "IMG_WIDTH = 75\n",
    "IMG_HEIGHT = 75\n",
    "BATCH_SIZE = 16\n",
    "\n",
    "def prepare_datasets(train_dataset_path, img_width, img_height, batch_size):\n",
    "    \"\"\"Prepares the datasets and dataloaders.\"\"\"\n",
    "    transform = transforms.Compose([\n",
    "        transforms.Resize((img_width, img_height)),\n",
    "        transforms.ToTensor()\n",
    "    ])\n",
    "    \n",
    "    # Load dataset\n",
    "    traffic_signals_dataset = datasets.ImageFolder(root=train_dataset_path, transform=transform)\n",
    "    \n",
    "    # Split dataset into training and validation sets\n",
    "    train_idx, valid_idx = train_test_split(\n",
    "        range(len(traffic_signals_dataset)),\n",
    "        test_size=0.1,\n",
    "        shuffle=True,\n",
    "        stratify=traffic_signals_dataset.targets\n",
    "    )\n",
    "\n",
    "    train_subset = Subset(traffic_signals_dataset, train_idx)\n",
    "    valid_subset = Subset(traffic_signals_dataset, valid_idx)\n",
    "\n",
    "    # Create dataloaders\n",
    "    train_loader = DataLoader(train_subset, batch_size=batch_size, shuffle=True)\n",
    "    valid_loader = DataLoader(valid_subset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "    return train_loader, valid_loader, traffic_signals_dataset.targets\n",
    "\n",
    "def display_class_distribution(targets):\n",
    "    \"\"\"Displays the class distribution of the dataset.\"\"\"\n",
    "    class_counts = {k: 0 for k in set(targets)}\n",
    "    for t in targets:\n",
    "        class_counts[t] += 1\n",
    "    print('Training class distribution:', class_counts)\n",
    "\n",
    "def main():\n",
    "    # Prepare datasets and dataloaders\n",
    "    train_loader, valid_loader, training_targets = prepare_datasets(\n",
    "        train_dataset_path, IMG_WIDTH, IMG_HEIGHT, BATCH_SIZE\n",
    "    )\n",
    "    \n",
    "    # Display class distribution\n",
    "    display_class_distribution(training_targets)\n",
    "    \n",
    "    # Initialize WGAN\n",
    "    wgan = WGAN()\n",
    "    \n",
    "    # Train WGAN\n",
    "    wgan.train(\n",
    "        dataset=train_loader, \n",
    "        n_epochs=200, \n",
    "        batch_size=BATCH_SIZE, \n",
    "        n_critic=5, \n",
    "        lr_generator=1e-4, \n",
    "        lr_discriminator=1e-4\n",
    "    )\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
